---
format:
  html:
    code-fold: show
    toc: true
    code-overflow: wrap
---

![](images/regression%20model.png)

**This code:**

-   implements all the transformed data into two linear models for evaluation
-   plots the residuals and linear regression

This is where it all comes together! After all the time and effort to construct my data pipeline and calculating variables.... running the linear model function was so simple yet illuminating.

### Fitting Linear Model One:

where the average change in crime rate is the dependent variable, and the average change in dispensary density is the independent variable.

```{r, warning=FALSE}
# import data
source("~/gvsu/winter 23/CIS 635/NIMBY/cleaning/linear_model/variables/crime and dispenaries per capita.R")
model1 <- lm(linear_variables$crime_yoy_avg ~ linear_variables$dsp_yoy_avg,  
             data = linear_variables)
```

### Interpreting the Results \| Mode 1

[*adapted from "[Residual Plots in R](https://www.youtube.com/watch?v=IMXRLNF0wY0 "Equitable Equations")"*]{style="font-size: 80%;"}

```{r}
library(tidyverse) # ggplot

# plot it
qplot(linear_variables$crime_yoy_avg, linear_variables$dsp_yoy_avg) + 
  geom_smooth(method = "lm") +
  xlab("Average Crime Rate") +
  ylab("Average Dispensary Density")

```

```{r}
summary(model1)
```

Regarding model 1, the shape of the graph reveals:

It appears that Model One is not a good fit for the data based on the negative initial adjusted R-squared value. Other insights I see from these results, include a slope of low magnitude indicating a weak relationship between variables. Additionally, the p-value of 0.62 is not strong enough to reject the null hypothesis at the level of significance (0.05)

because this linear model is so difficult to look at, I'm going to compare the residuals between the two models

```{r}
ggplot(model1, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.5, size =4, color ="#1679A6" ) +
  geom_hline(yintercept = 0
             , color = "#B41876") +
 labs(title='Model One Residual vs. Fitted Values Plot',
    x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```

### Model Two, adding in explanatory variables:

Race, Ethnicity, Poverty Rate, Employment

```{r}
#  y = YOY crime at the county level
model2 <- lm(linear_variables$crime_yoy_avg ~ linear_variables$dsp_yoy_avg +
               linear_variables$pct_poverty_rate  +
               linear_variables$pct_black  +
               linear_variables$pct_hispanic  +
               linear_variables$employeed_pop,
                data = linear_variables)



```

```{r}
library(ggplot2)


# Create a scatterplot of the residuals vs fitted values
mode2_plot <- ggplot(model2, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.5, size =4, color ="#1679A6" ) +
  geom_hline(yintercept = 0
             , color = "#B41876") +
 labs(title=' Replicated Model: Residual vs. Fitted Values Plot',
    x = "Fitted Values", y = "Residuals") +
  theme_minimal()

ggsave("images/model2.png")
mode2_plot
```

```{r}

summary(model2)
```

### Interpreting the Results \| Mode 2

Model 2 is also not an ideal fit for the data set, and I draw the same conclusions as above. Additionally looking at the residual vs predicted graph, the plots are not evenly distributed vertically, so model two is also not a good fit for this dataset.
